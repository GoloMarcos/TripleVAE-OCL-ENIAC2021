{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"word-embedding.ipynb","provenance":[],"collapsed_sections":[],"mount_file_id":"1WyKuuLGjlFK-3IXoW8NhjdnXNkXDV7f7","authorship_tag":"ABX9TyNHPmUdCORNV/VemeK269j5"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"K1-xA1rglT6p"},"source":["!gdown --id 1gKyva51VfHWNbVFVLWH-rnKvdoPpiEZG\n","!unzip Events.zip"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"VhktSGIZmdUW"},"source":["from os.path import isdir, isfile\n","from pathlib import Path\n","import numpy as np\n","import pandas as pd"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"xRp9ZD5Mml6f"},"source":["basepath = Path('./Events/')\n","files_in_basepath = basepath.iterdir()\n","datasets_dictionary = {}\n","for item in files_in_basepath:\n","  if item.is_file():\n","    df = pd.read_pickle('./Events/' + item.name)\n","    datasets_dictionary[item.name.replace('.plk','')] = df"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Lnan2I2rk_YQ","executionInfo":{"status":"ok","timestamp":1625589155077,"user_tz":180,"elapsed":7676,"user":{"displayName":"Marcos Paulo Silva Gôlo","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GibCQ81nR0vkq2Wa2jhFtwL5ubCet_iRF_FzWcukA=s64","userId":"00854347238887874462"}},"outputId":"a9d03bef-1430-4e18-ee48-5cec94abcc68"},"source":["!pip install -U sentence-transformers"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Collecting sentence-transformers\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/3b/fd/8a81047bbd9fa134a3f27e12937d2a487bd49d353a038916a5d7ed4e5543/sentence-transformers-2.0.0.tar.gz (85kB)\n","\u001b[K     |████████████████████████████████| 92kB 6.8MB/s \n","\u001b[?25hCollecting transformers<5.0.0,>=4.6.0\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/fd/1a/41c644c963249fd7f3836d926afa1e3f1cc234a1c40d80c5f03ad8f6f1b2/transformers-4.8.2-py3-none-any.whl (2.5MB)\n","\u001b[K     |████████████████████████████████| 2.5MB 15.8MB/s \n","\u001b[?25hRequirement already satisfied, skipping upgrade: tqdm in /usr/local/lib/python3.7/dist-packages (from sentence-transformers) (4.41.1)\n","Requirement already satisfied, skipping upgrade: torch>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from sentence-transformers) (1.9.0+cu102)\n","Requirement already satisfied, skipping upgrade: torchvision in /usr/local/lib/python3.7/dist-packages (from sentence-transformers) (0.10.0+cu102)\n","Requirement already satisfied, skipping upgrade: numpy in /usr/local/lib/python3.7/dist-packages (from sentence-transformers) (1.19.5)\n","Requirement already satisfied, skipping upgrade: scikit-learn in /usr/local/lib/python3.7/dist-packages (from sentence-transformers) (0.22.2.post1)\n","Requirement already satisfied, skipping upgrade: scipy in /usr/local/lib/python3.7/dist-packages (from sentence-transformers) (1.4.1)\n","Requirement already satisfied, skipping upgrade: nltk in /usr/local/lib/python3.7/dist-packages (from sentence-transformers) (3.2.5)\n","Collecting sentencepiece\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/ac/aa/1437691b0c7c83086ebb79ce2da16e00bef024f24fec2a5161c35476f499/sentencepiece-0.1.96-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2MB)\n","\u001b[K     |████████████████████████████████| 1.2MB 52.3MB/s \n","\u001b[?25hCollecting huggingface-hub\n","  Downloading https://files.pythonhosted.org/packages/35/03/071adc023c0a7e540cf4652fa9cad13ab32e6ae469bf0cc0262045244812/huggingface_hub-0.0.13-py3-none-any.whl\n","Requirement already satisfied, skipping upgrade: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from transformers<5.0.0,>=4.6.0->sentence-transformers) (4.5.0)\n","Requirement already satisfied, skipping upgrade: filelock in /usr/local/lib/python3.7/dist-packages (from transformers<5.0.0,>=4.6.0->sentence-transformers) (3.0.12)\n","Collecting tokenizers<0.11,>=0.10.1\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d4/e2/df3543e8ffdab68f5acc73f613de9c2b155ac47f162e725dcac87c521c11/tokenizers-0.10.3-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (3.3MB)\n","\u001b[K     |████████████████████████████████| 3.3MB 38.7MB/s \n","\u001b[?25hRequirement already satisfied, skipping upgrade: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers<5.0.0,>=4.6.0->sentence-transformers) (2019.12.20)\n","Requirement already satisfied, skipping upgrade: pyyaml in /usr/local/lib/python3.7/dist-packages (from transformers<5.0.0,>=4.6.0->sentence-transformers) (3.13)\n","Collecting sacremoses\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/75/ee/67241dc87f266093c533a2d4d3d69438e57d7a90abb216fa076e7d475d4a/sacremoses-0.0.45-py3-none-any.whl (895kB)\n","\u001b[K     |████████████████████████████████| 901kB 46.8MB/s \n","\u001b[?25hRequirement already satisfied, skipping upgrade: packaging in /usr/local/lib/python3.7/dist-packages (from transformers<5.0.0,>=4.6.0->sentence-transformers) (20.9)\n","Requirement already satisfied, skipping upgrade: requests in /usr/local/lib/python3.7/dist-packages (from transformers<5.0.0,>=4.6.0->sentence-transformers) (2.23.0)\n","Requirement already satisfied, skipping upgrade: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch>=1.6.0->sentence-transformers) (3.7.4.3)\n","Requirement already satisfied, skipping upgrade: pillow>=5.3.0 in /usr/local/lib/python3.7/dist-packages (from torchvision->sentence-transformers) (7.1.2)\n","Requirement already satisfied, skipping upgrade: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->sentence-transformers) (1.0.1)\n","Requirement already satisfied, skipping upgrade: six in /usr/local/lib/python3.7/dist-packages (from nltk->sentence-transformers) (1.15.0)\n","Requirement already satisfied, skipping upgrade: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->transformers<5.0.0,>=4.6.0->sentence-transformers) (3.4.1)\n","Requirement already satisfied, skipping upgrade: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers<5.0.0,>=4.6.0->sentence-transformers) (7.1.2)\n","Requirement already satisfied, skipping upgrade: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->transformers<5.0.0,>=4.6.0->sentence-transformers) (2.4.7)\n","Requirement already satisfied, skipping upgrade: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers<5.0.0,>=4.6.0->sentence-transformers) (2021.5.30)\n","Requirement already satisfied, skipping upgrade: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers<5.0.0,>=4.6.0->sentence-transformers) (1.24.3)\n","Requirement already satisfied, skipping upgrade: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers<5.0.0,>=4.6.0->sentence-transformers) (2.10)\n","Requirement already satisfied, skipping upgrade: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers<5.0.0,>=4.6.0->sentence-transformers) (3.0.4)\n","Building wheels for collected packages: sentence-transformers\n","  Building wheel for sentence-transformers (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for sentence-transformers: filename=sentence_transformers-2.0.0-cp37-none-any.whl size=126711 sha256=26f95ed6808e509f066d85ebecd8c5b36dadf022b462a22dc01dbce8a2e0c2db\n","  Stored in directory: /root/.cache/pip/wheels/38/d2/98/d191289a877a34c68aa67e05179521e060f96394a3e9336be6\n","Successfully built sentence-transformers\n","\u001b[31mERROR: transformers 4.8.2 has requirement huggingface-hub==0.0.12, but you'll have huggingface-hub 0.0.13 which is incompatible.\u001b[0m\n","Installing collected packages: tokenizers, sacremoses, huggingface-hub, transformers, sentencepiece, sentence-transformers\n","Successfully installed huggingface-hub-0.0.13 sacremoses-0.0.45 sentence-transformers-2.0.0 sentencepiece-0.1.96 tokenizers-0.10.3 transformers-4.8.2\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"8x4MZnYZlItM"},"source":["from sentence_transformers import SentenceTransformer"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"wGqCSIu1lLXx"},"source":["def WordEmbeddings(sentences):\n","\n","  model = SentenceTransformer('distiluse-base-multilingual-cased')\n","\n","  sentence_embeddings = model.encode(sentences)\n","\n","  return sentence_embeddings "],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"2HAecWf4lTKA"},"source":["for base in datasets_dictionary.keys():\n","  \n","  df = datasets_dictionary[base]\n","\n","  df2 = pd.DataFrame()\n","  for column in df.columns:\n","    df2[column] = df[column]\n","\n","  embeddings = WordEmbeddings(df.Title)\n","  df2['DBERTML'] = list(np.array(embeddings))\n","\n","  name = base + '.plk'\n","  df2.to_pickle(name)\n","  print(name + ' Done!')"],"execution_count":null,"outputs":[]}]}